{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import bs4\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import re\n",
    "import gspread\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from df2gspread import df2gspread as d2g\n",
    "import datetime\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import numpy as np\n",
    "import random\n",
    "from selenium.webdriver import ActionChains\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"../creds.json\", scope)\n",
    "client = gspread.authorize(creds)\n",
    "sheet = client.open(\"stock data\")\n",
    "sheet = sheet.worksheet(\"crypto\")\n",
    "df = pd.DataFrame(sheet.get_all_values())\n",
    "df.columns = df.iloc[0]\n",
    "df = df.iloc[1:]\n",
    "df = df.replace('N/A', np.nan)\n",
    "df= df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope = ['https://www.googleapis.com/auth/drive']\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name(\"../creds.json\", scope)\n",
    "client = gspread.authorize(creds)\n",
    "sheet = client.open(\"stock data1\")\n",
    "sheet = sheet.worksheet(\"crypto\")\n",
    "df1 = pd.DataFrame(sheet.get_all_values())\n",
    "df1.columns = df1.iloc[0]\n",
    "df1 = df1.iloc[1:]\n",
    "df1 = df1.replace('N/A', np.nan)\n",
    "df1= df1.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = df.append(df1)\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = allData.reset_index()\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allData = allData.drop(columns = ['index'])\n",
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allData.to_csv('../crypto.csv',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_to_float(x):\n",
    "    if type(x) == float or type(x) == int:\n",
    "        return x\n",
    "    if \",\" in x:\n",
    "        x = x.replace(',', '')\n",
    "    if 'K' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('K', '')) * 1000\n",
    "        return 1000.0\n",
    "    if 'T' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('T', '')) * 1000000000\n",
    "        return 1000000.0\n",
    "    if 'M' in x:\n",
    "        if len(x) > 1:\n",
    "            return float(x.replace('M', '')) * 1000000\n",
    "        return 1000000.0\n",
    "    if 'B' in x:\n",
    "        return float(x.replace('B', '')) * 1000000000\n",
    "    return float(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Total Volume All Currencies (24Hr)\"] = [value_to_float(x) for x in df[\"Total Volume All Currencies (24Hr)\"]]\n",
    "df[\"Volume in Currency (Since 0:00 UTC)\"] = [value_to_float(x) for x in df[\"Volume in Currency (Since 0:00 UTC)\"]]\n",
    "df[\"Volume in Currency (24Hr)\"] = [value_to_float(x) for x in df[\"Volume in Currency (24Hr)\"]]\n",
    "df['Circulating Supply'] = [value_to_float(x) for x in df['Circulating Supply']]\n",
    "df['52 Week Range'] = [value_to_float(x) for x in df['52 Week Range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Change'] = [s.replace(',', '').replace('+', '') for s in df['Change']]\n",
    "df[\"Price (Intraday)\"] = [s.replace(',', '') for s in df[\"Price (Intraday)\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['time'] = [datetime.datetime.strptime(s[4:], '%b %d %H:%M:%S %Y') for s in df['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbh = ['BSV-USD','BTC-USD', 'BCH-USD','LTC-USD','ETH-USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'Change': float, \"Price (Intraday)\": float, \"Total Volume All Currencies (24Hr)\": float, \"Volume in Currency (Since 0:00 UTC)\": float, \"Volume in Currency (24Hr)\": float, 'Circulating Supply':float,'52 Week Range': float})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = '% Change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df['time'])[0].hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day of week'] = [t.weekday() for t in df['time']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour of day'] = [t.hour for t in df['time']]\n",
    "df\n",
    "df = df[df['hour of day'] != 22]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timedelta'] = [(datetime.datetime.now() - x).total_seconds() for x in df['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['6 hour diff'] = df.groupby('Symbol')['Price (Intraday)'].diff() * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['% 6 hour diff'] = df['6 hour diff']/ (df['Price (Intraday)'] - df['6 hour diff']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotDOW = pd.get_dummies(df['day of week'],prefix='dow')\n",
    "oHDOWcols = oneHotDOW.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list(oHDOWcols)] = oneHotDOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'day of week')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneHotHOD = pd.get_dummies(df['hour of day'],prefix='hod')\n",
    "oHHODcols = oneHotHOD.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[list(oHHODcols )] = oneHotHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = 'hour of day')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfNoOH = df.iloc[:,:13]\n",
    "dfNoOH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', df.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def knn(data, k, test_size, train_size, guess):\n",
    "    \n",
    "#     data = data.drop(columns = 'time')\n",
    "#     test = data.drop(columns = ['Name', 'Symbol'])\n",
    "#     if not guess:\n",
    "#         test = test.dropna()\n",
    "#     X = test.drop(columns = ['% 6 hour diff', '6 hour diff'])\n",
    "#     y = test['quartile'].astype(int)\n",
    "#     scaler = StandardScaler() \n",
    "#     X = scaler.fit_transform(X)\n",
    "    \n",
    "#     X_train = X[test_size:test_size + train_size]\n",
    "#     X_test = X[:test_size]\n",
    "\n",
    "    \n",
    "#     y_train = y[test_size:test_size + train_size]\n",
    "#     y_test = y[:test_size]\n",
    "    \n",
    "#     model = KNeighborsClassifier(n_neighbors=k)\n",
    "#     model.fit(X_train,y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     return y_pred, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(data, k, test_size, train_size, guess, q):\n",
    "    \n",
    "    bins = q\n",
    "    qs = list(data['% 6 hour diff'].quantile(np.linspace(0,1, bins + 1)[1:bins]))\n",
    "    qs\n",
    "    quartile = []\n",
    "    for x in data['% 6 hour diff']:\n",
    "        for i in range(bins):\n",
    "            if i == bins -1:\n",
    "                quartile.append(i)\n",
    "                break\n",
    "            if x < qs[i]:\n",
    "                quartile.append(i)\n",
    "                break \n",
    "    data['quartile'] = quartile\n",
    "    \n",
    "    \n",
    "    data = data.drop(columns = 'time')\n",
    "    test = data.drop(columns = ['Name', 'Symbol'])\n",
    "    if not guess:\n",
    "        test = test.dropna()\n",
    "        \n",
    "    X = test.drop(columns = ['% 6 hour diff', '6 hour diff'])\n",
    "    y = test['quartile'].astype(int)\n",
    "    scaler = StandardScaler() \n",
    "    X = scaler.fit_transform(X)\n",
    "    \n",
    "    X_train = X[test_size:test_size + train_size]\n",
    "    X_test = X[:test_size]\n",
    "\n",
    "    \n",
    "    y_train = y[test_size:test_size + train_size]\n",
    "    y_test = y[:test_size]\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred, y_test, qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbh = ['ETH-USD','BTC-USD','LTC-USD','BCH-USD', 'BSV-USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allResults = pd.DataFrame()\n",
    "for q in range(2, 15):\n",
    "    p, t, qs = knn(df, 10, 30, 10000, True,q)\n",
    "    results = df.iloc[:15]\n",
    "    results['bins'] = [q] * 15\n",
    "    results['guess'] = p[:15]\n",
    "    maxProjs = []\n",
    "    maxVals = []\n",
    "    for i in range(len(results['guess'])):\n",
    "        guess = results['guess'][i]\n",
    "        currVal = results['Price (Intraday)'][i]\n",
    "        if guess == 0:\n",
    "            maxP = 'x < ' + str(qs[guess]) \n",
    "            maxVal = 'x < ' + str(qs[guess]/100 * currVal + currVal) \n",
    "        elif guess == q - 1:\n",
    "            maxP =  str(qs[guess -1]) + ' < x'\n",
    "            maxVal= str(qs[guess -1]/100 * currVal + currVal) + ' < x'\n",
    "        else:\n",
    "            maxP = str(qs[guess - 1]) + ' < ' + ' x ' + ' < ' + str(qs[guess])\n",
    "            maxVal = str(qs[guess - 1]/100 * currVal + currVal) + ' < ' + ' x ' + ' < ' + str(qs[guess]/ 100 * currVal + currVal)\n",
    "        maxVals.append(maxVal)\n",
    "        maxProjs.append(maxP)\n",
    "    results['max value'] = maxVals\n",
    "    results['max %'] = maxProjs\n",
    "    allResults = allResults.append(results[['Symbol','Name','Price (Intraday)','bins', 'guess', 'max %','max value']])\n",
    "allResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = []\n",
    "for x in allResults['Symbol']:\n",
    "    if x in rbh:\n",
    "        keep.append(True)\n",
    "    else:\n",
    "        keep.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = allResults[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = allResults.sort_values(['Symbol', 'bins'])\n",
    "allResultsOneHot = allResults\n",
    "allResultsOneHot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "allResults = pd.DataFrame()\n",
    "for q in range(2, 15):\n",
    "    p, t, qs = knn(dfNoOH, 10, 30, 10000, True,q)\n",
    "    results = df.iloc[:15]\n",
    "    results['bins'] = [q] * 15\n",
    "    results['guess'] = p[:15]\n",
    "    maxProjs = []\n",
    "    maxVals = []\n",
    "    for i in range(len(results['guess'])):\n",
    "        guess = results['guess'][i]\n",
    "        currVal = results['Price (Intraday)'][i]\n",
    "        if guess == 0:\n",
    "            maxP = 'x < ' + str(qs[guess]) \n",
    "            maxVal = 'x < ' + str(qs[guess]/100 * currVal + currVal) \n",
    "        elif guess == q - 1:\n",
    "            maxP =  str(qs[guess -1]) + ' < x'\n",
    "            maxVal= str(qs[guess -1]/100 * currVal + currVal) + ' < x'\n",
    "        else:\n",
    "            maxP = str(qs[guess - 1]) + ' < ' + ' x ' + ' < ' + str(qs[guess])\n",
    "            maxVal = str(qs[guess - 1]/100 * currVal + currVal) + ' < ' + ' x ' + ' < ' + str(qs[guess]/ 100 * currVal + currVal)\n",
    "        maxVals.append(maxVal)\n",
    "        maxProjs.append(maxP)\n",
    "    results['max value'] = maxVals\n",
    "    results['max %'] = maxProjs\n",
    "    allResults = allResults.append(results[['Symbol','Name','Price (Intraday)','bins', 'guess', 'max %','max value']])\n",
    "allResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', df.shape[0]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = []\n",
    "for x in allResults['Symbol']:\n",
    "    if x in rbh:\n",
    "        keep.append(True)\n",
    "    else:\n",
    "        keep.append(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = allResults[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults = allResults.sort_values(['Symbol', 'bins'])\n",
    "allResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #TESTER\n",
    "\n",
    "scores = pd.DataFrame(columns=['Symbol', 'Current Price', \"bins\", \"average accuracy\",'guess',\"max %\",'max value','true positive rate','pred > true','pred < true','pred < q0'])\n",
    "\n",
    "for symbol in rbh:\n",
    "    data = df[df['Symbol'] == symbol]\n",
    "    currVal = list(data['Price (Intraday)'])[0]\n",
    "    print(symbol)\n",
    "\n",
    "    for x in range(2,18):\n",
    "        bins = x\n",
    "#         qs = list(data['% 6 hour diff'].quantile(np.linspace(0,1, bins + 1)[1:bins]))\n",
    "#         quartile = []\n",
    "#         for x in data['% 6 hour diff']:\n",
    "#             for i in range(bins):\n",
    "#                 if i == bins -1:\n",
    "#                     quartile.append(i)\n",
    "#                     break\n",
    "#                 if x < qs[i]:\n",
    "#                     quartile.append(i)\n",
    "#                     break \n",
    "#         data['quartile'] = quartile\n",
    "\n",
    "        samples = 800\n",
    "        if symbol == 'BSV-USD':\n",
    "            samples = 120\n",
    "        train_size = 248\n",
    "        test_size = 2\n",
    "        # for k in range(1,6):\n",
    "\n",
    "\n",
    "        k = 10\n",
    "        p1 = []\n",
    "        t1 = []\n",
    "        for y in range(1, samples):\n",
    "            test = data.iloc[y:]\n",
    "            p, t, bb = knn(test, k, test_size, train_size, False, x)\n",
    "            p1.append(p[0])\n",
    "            t1.append(t.iloc[0])\n",
    "        avgr2 = metrics.accuracy_score(t1,p1)\n",
    "        predss = pd.DataFrame({'y_pred':p1, 'y_test':t1, '% 6 hour diff' : list(data['% 6 hour diff'])[1:len(p1)+1]})\n",
    "        tp = 0\n",
    "        pGt = 0\n",
    "        pLt = 0\n",
    "        pG0 = 0\n",
    "        \n",
    "\n",
    "    #     tp = tp/len(predss['y_pred']) * 100\n",
    "    #     pGt = pGt/len(predss['y_pred']) * 100\n",
    "    #     pLt = pLt/len(predss['y_pred']) * 100\n",
    "    #     pG0 = pG0/len(predss['y_pred']) * 100\n",
    "\n",
    "\n",
    "\n",
    "        p, t, qs = knn(data, k, test_size, train_size, True, x)\n",
    "        for i in range(len(qs)):\n",
    "            if qs[i] > 0:\n",
    "                qInd = i\n",
    "                break\n",
    "        guess = list(p)[0]\n",
    "        predsProj = pd.DataFrame({'y_pred':p1, 'y_test':t1})\n",
    "        \n",
    "\n",
    "\n",
    "        predss = predss[predss['y_pred'] == guess]\n",
    "        for i in range(len(predss['y_pred'])):\n",
    "            pred = list(predss['y_pred'])[i]\n",
    "            test = list(predss['y_test'])[i]\n",
    "            if pred == test:\n",
    "                tp += 1\n",
    "            elif pred > test:\n",
    "                pGt += 1\n",
    "            elif pred < test:\n",
    "                pLt += 1\n",
    "                if pred <= qInd:\n",
    "                    pG0 += 1\n",
    "        if guess == 0:\n",
    "            maxP = 'x < ' + str(qs[guess]) \n",
    "        elif guess == bins - 1:\n",
    "            maxP =  str(qs[guess -1]) + ' < x'\n",
    "        else:\n",
    "            maxP = str(qs[guess - 1]) + ' < ' + ' x ' + ' < ' + str(qs[guess])\n",
    "        if guess == 0:\n",
    "            maxVal = 'x < ' + str(qs[guess]/100 * currVal + currVal) \n",
    "        elif guess == bins - 1:\n",
    "            maxVal= str(qs[guess -1]/100 * currVal + currVal) + ' < x'\n",
    "        else:\n",
    "            maxVal = str(qs[guess - 1]/100 * currVal + currVal) + ' < ' + ' x ' + ' < ' + str(qs[guess]/ 100 * currVal + currVal)\n",
    "        scores = scores.append({'Symbol': symbol,\n",
    "                                'Current Price': currVal,\n",
    "                            'bins': bins,\n",
    "                            \"average accuracy\": avgr2,\n",
    "                                'guess' : guess,\n",
    "                               \"max %\": maxP,\n",
    "                               'max value' : maxVal,\n",
    "                               'true positive rate': tp,\n",
    "                               'pred > true': pGt,\n",
    "                               'pred < true': pLt,\n",
    "                               'pred < q0': pG0,\n",
    "                               'q0': qs[qInd]}, ignore_index=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allResultsOneHot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[df['Symbol'] == 'ETH-USD']\n",
    "x = 3\n",
    "p1 = []\n",
    "t1 = []\n",
    "for y in range(0, samples):\n",
    "    test = data.iloc[y:]\n",
    "    p, t = knn(test, k, test_size, train_size, False, x)\n",
    "    p1.append(p[0])\n",
    "    t1.append(t.iloc[0])\n",
    "avgr2 = metrics.accuracy_score(t1,p1)\n",
    "predss = pd.DataFrame({'y_pred':p1, 'y_test':t1, '% 6 hour diff' : list(data['% 6 hour diff'])[1:len(p1)+1]})\n",
    "y_true = predss['y_test']\n",
    "y_pred = predss['y_pred']\n",
    "unique_label = list(set(y_true))\n",
    "pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_true, y_pred, labels=unique_label), \n",
    "    index=['true:{:}'.format(x) for x in unique_label], \n",
    "    columns=['pred:{:}'.format(x) for x in unique_label]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avgr2)\n",
    "predss.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 30\n",
    "trainSize = 10000\n",
    "k = 10\n",
    "q = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, t, qs= knn(dfNoOH, k,testSize, trainSize, False,q)\n",
    "metrics.accuracy_score(p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, t, qs= knn(df,  k,testSize, trainSize, False,q)\n",
    "metrics.accuracy_score(p,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 17\n",
    "qs = list(eth['% 6 hour diff'].quantile(np.linspace(0,1, bins + 1)[1:bins]))\n",
    "qs\n",
    "quartile = []\n",
    "for x in eth['% 6 hour diff']:\n",
    "    for i in range(bins):\n",
    "        if i == bins -1:\n",
    "            quartile.append(i)\n",
    "            break\n",
    "        if x < qs[i]:\n",
    "            quartile.append(i)\n",
    "            break \n",
    "eth['quartile'] = quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LONG TERM\n",
    "minR2 = 0\n",
    "ind = 0\n",
    "xx = 0\n",
    "data = eth\n",
    "tests = pd.DataFrame(columns=[\"test size\", \"train size\", \"k neighbors\", \"average accuracy\",])\n",
    "# for k in range(1,12):\n",
    "k = 1\n",
    "for x in range(248, 250):\n",
    "    print(x)\n",
    "    for i in range(1, 3):\n",
    "        avgr2 = 0\n",
    "        p1 = []\n",
    "        t1 = []\n",
    "        for y in range(1, 800):\n",
    "            test = data.iloc[y:]\n",
    "            p, t = knn(test, k, i, x, False, bins)\n",
    "            p1.append(p[0])\n",
    "            t1.append(t.iloc[0])\n",
    "        avgr2 = metrics.accuracy_score(t1,p1)\n",
    "        tests = tests.append({\"test size\": i,\n",
    "                        \"train size\": x,\n",
    "                        \"k neighbors\": k,\n",
    "                        \"average accuracy\": avgr2}, ignore_index=True)\n",
    "        if minR2 < avgr2 and avgr2 < 1:\n",
    "            minR2 = avgr2\n",
    "            ind = i\n",
    "            xx = x\n",
    "            ts = t1\n",
    "            ps = p1          \n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tests = tests.sort_values('average accuracy', ascending = False).head(40)\n",
    "guesses = []\n",
    "for i in range(len(list(tests['train size']))):\n",
    "    p, t = knn(eth, int(list(tests[\"k neighbors\"])[i]), int(list(tests['test size'])[i]), int(list(tests['train size'])[i]), True, bins)\n",
    "    predsProj = pd.DataFrame({'y_pred':p, 'y_test':t})\n",
    "    guess = list(predsProj['y_pred'])[0]\n",
    "    guesses.append(guess)\n",
    "tests['guess'] = guesses  \n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', df.shape[0]+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predss = pd.DataFrame({'y_pred':ps, 'y_test':ts, '% 6 hour diff' : list(eth['% 6 hour diff'])[1:len(ps)+1]})\n",
    "display(predss[predss['y_pred'] == list(tests['guess'])[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = predss['y_test']\n",
    "y_pred = predss['y_pred']\n",
    "unique_label = list(set(y_true))\n",
    "pd.DataFrame(\n",
    "    metrics.confusion_matrix(y_true, y_pred, labels=unique_label), \n",
    "    index=['true:{:}'.format(x) for x in unique_label], \n",
    "    columns=['pred:{:}'.format(x) for x in unique_label]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(predss['y_test'], predss['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUESS FOR 100 of the last values, train (115-150), test (1-3), 5 neighbors \n",
    "#and practically\n",
    "#GUESS FOR 100 of the last values, train (1-150), test (2-100), 5 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests = tests.sort_values('average accuracy', ascending = False).head(40)\n",
    "# guesses = []\n",
    "# for i in range(40):\n",
    "#     p, t = knn(eth, int(list(tests[\"k neighbors\"])[i]), int(list(tests['test size'])[i]), int(list(tests['train size'])[i]), True)\n",
    "#     predsProj = pd.DataFrame({'y_pred':p, 'y_test':t})\n",
    "#     guess = list(predsProj['y_pred'])[0]\n",
    "#     guesses.append(guess)\n",
    "# tests['guess'] = guesses  \n",
    "# tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHORT TERM\n",
    "minR2 = 0\n",
    "ind = 0\n",
    "xx = 0\n",
    "data = eth\n",
    "tests = pd.DataFrame(columns=[\"test size\", \"train size\", \"k neighbors\", \"average accuracy\",])\n",
    "\n",
    "k =5\n",
    "# for k in range(1,12):\n",
    "for x in range(70, 80):\n",
    "    print(x)\n",
    "    for i in range(22, 30):\n",
    "        avgr2 = 0\n",
    "        p1 = []\n",
    "        t1 = []\n",
    "        for y in range(1, 500):\n",
    "            test = data.iloc[y:]\n",
    "            p, t = knn(test, k, i, x, False)\n",
    "            p1.append(p[0])\n",
    "            t1.append(t.iloc[0])\n",
    "        avgr2 = metrics.accuracy_score(t1,p1)\n",
    "        tests = tests.append({\"test size\": i,\n",
    "                        \"train size\": x,\n",
    "                        \"k neighbors\": k,\n",
    "                        \"average accuracy\": avgr2}, ignore_index=True)\n",
    "        if minR2 < avgr2 and avgr2 < 1:\n",
    "            minR2 = avgr2\n",
    "            ind = i\n",
    "            xx = x\n",
    "            ts = t1\n",
    "            ps = p1          \n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUESS FOR 15 of the last values, train (65 - 79), test (22-30), 5 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tests = tests.sort_values('average accuracy', ascending = False).head(40)\n",
    "guesses = []\n",
    "for i in range(40):\n",
    "    p, t = knn(eth, int(list(tests[\"k neighbors\"])[i]), int(list(tests['test size'])[i]), int(list(tests['train size'])[i]), True)\n",
    "    predsProj = pd.DataFrame({'y_pred':p, 'y_test':t})\n",
    "    guess = list(predsProj['y_pred'])[0]\n",
    "    guesses.append(guess)\n",
    "tests['guess'] = guesses  \n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['guess'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predss = pd.DataFrame({'y_pred':ps, 'y_test':ts})\n",
    "predss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = list(eth['% 6 hour diff'].quantile([.25,0.5,.75]))\n",
    "qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(quartile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quartile = []\n",
    "for x in eth['% 6 hour diff']:\n",
    "    if x < qs[0]:\n",
    "        quartile.append(0)\n",
    "    elif x < qs[1]:\n",
    "        quartile.append(1)\n",
    "    elif x < qs[2]:\n",
    "        quartile.append(2)\n",
    "    else:\n",
    "        quartile.append(3)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eth['quartile'] = quartile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LONG TERM\n",
    "minR2 = 0\n",
    "ind = 0\n",
    "xx = 0\n",
    "data = eth\n",
    "tests = pd.DataFrame(columns=[\"test size\", \"train size\", \"k neighbors\", \"average accuracy\",])\n",
    "# for k in range(1,12):\n",
    "k = 5\n",
    "for x in range(110, 150):\n",
    "    print(x)\n",
    "    for i in range(1, 3):\n",
    "        avgr2 = 0\n",
    "        p1 = []\n",
    "        t1 = []\n",
    "        for y in range(1, 100):\n",
    "            test = data.iloc[y:]\n",
    "            p, t = knn(test, 5, i, x, False)\n",
    "            p1.append(p[0])\n",
    "            t1.append(t.iloc[0])\n",
    "        avgr2 = metrics.accuracy_score(t1,p1)\n",
    "        tests = tests.append({\"test size\": i,\n",
    "                        \"train size\": x,\n",
    "                        \"k neighbors\": k,\n",
    "                        \"average accuracy\": avgr2}, ignore_index=True)\n",
    "        if minR2 < avgr2 and avgr2 < 1:\n",
    "            minR2 = avgr2\n",
    "            ind = i\n",
    "            xx = x\n",
    "            ts = t1\n",
    "            ps = p1          \n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = tests.sort_values('average accuracy', ascending = False).head(40)\n",
    "guesses = []\n",
    "for i in range(40):\n",
    "    p, t = knn(eth, int(list(tests[\"k neighbors\"])[i]), int(list(tests['test size'])[i]), int(list(tests['train size'])[i]), True)\n",
    "    predsProj = pd.DataFrame({'y_pred':p, 'y_test':t})\n",
    "    guess = list(predsProj['y_pred'])[0]\n",
    "    guesses.append(guess)\n",
    "tests['guess'] = guesses  \n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predss = pd.DataFrame({'y_pred':ps, 'y_test':ts})\n",
    "predss.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHORT TERM\n",
    "minR2 = 0\n",
    "ind = 0\n",
    "xx = 0\n",
    "data = eth\n",
    "tests = pd.DataFrame(columns=[\"test size\", \"train size\", \"k neighbors\", \"average accuracy\",])\n",
    "\n",
    "k =5\n",
    "# for k in range(1,12):\n",
    "for x in range(50, 80):\n",
    "    print(x)\n",
    "    for i in range(22, 30):\n",
    "        avgr2 = 0\n",
    "        p1 = []\n",
    "        t1 = []\n",
    "        for y in range(1, 20):\n",
    "            test = data.iloc[y:]\n",
    "            p, t = knn(test, k, i, x, False)\n",
    "            p1.append(p[0])\n",
    "            t1.append(t.iloc[0])\n",
    "        avgr2 = metrics.accuracy_score(t1,p1)\n",
    "        tests = tests.append({\"test size\": i,\n",
    "                        \"train size\": x,\n",
    "                        \"k neighbors\": k,\n",
    "                        \"average accuracy\": avgr2}, ignore_index=True)\n",
    "        if minR2 < avgr2 and avgr2 < 1:\n",
    "            minR2 = avgr2\n",
    "            ind = i\n",
    "            xx = x\n",
    "            ts = t1\n",
    "            ps = p1          \n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GUESS FOR 15 of the last values, train (65 - 79), test (22-30), 5 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tests = tests.sort_values('average accuracy', ascending = False).head(40)\n",
    "guesses = []\n",
    "for i in range(40):\n",
    "    p, t = knn(eth, int(list(tests[\"k neighbors\"])[i]), int(list(tests['test size'])[i]), int(list(tests['train size'])[i]), True)\n",
    "    predsProj = pd.DataFrame({'y_pred':p, 'y_test':t})\n",
    "    guess = list(predsProj['y_pred'])[0]\n",
    "    guesses.append(guess)\n",
    "tests['guess'] = guesses  \n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests['guess'].value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predss = pd.DataFrame({'y_pred':ps, 'y_test':ts})\n",
    "predss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tests = tests.sort_values('average accuracy', ascending = False).head(40)\n",
    "guesses = []\n",
    "for i in range(40):\n",
    "    p, t = knn(eth, int(list(tests['test size'])[i]), int(list(tests['train size'])[i]), True)\n",
    "    predsProj = pd.DataFrame({'y_pred':p, 'y_test':t})\n",
    "    guess = list(predsProj['y_pred'])[0]\n",
    "    guesses.append(guess)\n",
    "tests['guess'] = guesses  \n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bch = df[df['Symbol'] == 'BCH-USD']\n",
    "ltc = df[df['Symbol'] == 'LTC-USD']\n",
    "zec = df[df['Symbol'] == 'ZEC-USD']\n",
    "xrp = df[df['Symbol'] == 'XRP-USD']\n",
    "xmr = df[df['Symbol'] == 'XMR-USD']\n",
    "neo = df[df['Symbol'] == 'NEO-USD']\n",
    "dash = df[df['Symbol'] == 'DASH-USD']\n",
    "xlm = df[df['Symbol'] == 'XLM-USD']\n",
    "bsv = df[df['Symbol'] == 'BSV-USD']\n",
    "eth = df[df['Symbol'] == 'ETH-USD']\n",
    "btc = df[df['Symbol'] == 'BTC-USD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns = ['Symbol', 'cutoff', 'accuracy', 'over cutoff'])\n",
    "for frame in frames:\n",
    "    sym = list(frame['Symbol'])[0]\n",
    "    for i in np.arange(0,10, .05):\n",
    "        try:\n",
    "            p, t, per, act = logRegressionScaled(frame, i)\n",
    "            acc = metrics.accuracy_score(t, p)\n",
    "            act = act[0]\n",
    "            result = result.append({\"Symbol\" : sym,\n",
    "                                            'cutoff': i, \n",
    "                                            \"accuracy\": acc, \n",
    "                                            \"over cutoff\": act}, ignore_index=True)\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[(result['over cutoff']) & (result['Symbol'] == 'ETH-USD')].sort_values('cutoff', ascending = False).head(40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
